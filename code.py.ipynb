{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a24dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import InceptionResNetV2 #299\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D ,Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load(path,target_size,arg = 'yes'):\n",
    "  ret_data = []\n",
    "  ret_label = []\n",
    "  ret_name = []\n",
    "  count = 0\n",
    "\n",
    "  for i in path: #path is a list of folder path\n",
    "    file_list = os.listdir(i)\n",
    "    # Filter out non-image files (if any)\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    img_files = [f for f in file_list if os.path.splitext(f)[1].lower() in img_extensions]\n",
    "    for f in img_files: #f is image name is the folder\n",
    "        img_path = os.path.join(i, f)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize(target_size)\n",
    "        \n",
    "        # Original image\n",
    "        img_array = np.array(img)\n",
    "        label = np.zeros(120)\n",
    "        label[count] = 1 #Create one-hot encoding label\n",
    "        ret_data.append(img_array)\n",
    "        ret_label.append(label)\n",
    "        ret_name.append(f)\n",
    "        \n",
    "        \n",
    "    count += 1\n",
    "  \n",
    "\n",
    "        \n",
    "  ret_data , ret_label , ret_name = np.array(ret_data),np.array(ret_label),np.array(ret_name)\n",
    "  return ret_data,ret_label,ret_name\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #load .mat file\n",
    "    file_name  = \"C:/Users/88696/Desktop/HW3 data/stanford_dogs/stanfor_dogs\"\n",
    "    \n",
    "    base_model = InceptionResNetV2(include_top= False, input_shape= (224, 224, 3), weights= 'imagenet')\n",
    "\n",
    "    \n",
    "    for layer in base_model.layers[0:len(base_model.layers)-20]:  \n",
    "       layer.trainable = False\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Add your custom top layer\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(120,activation='softmax'))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "    \n",
    "    # Create the full model\n",
    "    model.summary()\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Create an instance of ImageDataGenerator\n",
    "    \n",
    "    train_datagen  = ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        validation_split=0.15\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "    \n",
    "    # load and iterate training dataset\n",
    "    train_it = train_datagen.flow_from_directory('C:/Users/88696/Desktop/HW3 data/stanford_dogs/stanfor_dogs/train', \n",
    "                                                 class_mode='categorical', \n",
    "                                                 batch_size=64, \n",
    "                                                 target_size=(224, 224),\n",
    "                                                 subset='training'\n",
    "                                                 )\n",
    "    \n",
    "    val_it = train_datagen.flow_from_directory('C:/Users/88696/Desktop/HW3 data/stanford_dogs/stanfor_dogs/train', \n",
    "                                                 class_mode='categorical', \n",
    "                                                 batch_size=64, \n",
    "                                                 target_size=(224, 224),\n",
    "                                                 subset='validation'\n",
    "                                                 )\n",
    "    \n",
    "    \n",
    "    callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "    history = model.fit(train_it, validation_data=val_it, epochs=50, steps_per_epoch=len(train_it), \n",
    "           callbacks=callbacks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot the training and validation accuracy\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot the training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "        \n",
    "    #predicting test data\n",
    "    test_path = [file_name+\"/test\"]\n",
    "    test_data , test_label , test_name = load(test_path,(224,224))\n",
    "    result = model.predict(test_data)\n",
    "    predicted_labels = np.argmax(result, axis=1)\n",
    "    #store in xlsx file\n",
    "    df = pd.DataFrame({\n",
    "    'Name': test_name,\n",
    "    'Label': predicted_labels\n",
    "    })\n",
    "    \n",
    "    df.to_excel('C:/Users/88696/Desktop/HW3 data/result.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
